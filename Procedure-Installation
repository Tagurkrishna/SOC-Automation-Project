Installation of VM Ware of Windows Machine

Before Installing Any VM Ware
Example : Oracle VM Ware Download SHA256 File and recheck after downloading the VM Ware
To Recheck copy the path you placed the downloaded file and open windows power shell and use command : Get-FileHash .\"FileName" (FileName Copy Paste from propety) Once the SHA256 Value Matches then install it.

It is one more prevention method to stay safe from any unknown file or wrong file getting install and being secure with other attackers.

Install Any windows 10 or Later

Requirement: 
Ram 3GB(Recommeded) or Higher
Storage : 50 GB
Processor : Least 1 Processor

Start VM Ware and Complete the installation.

After logging Install Sysmon
Use the link below for Downloading and Sysmon Config file : https://github.com/Tagurkrishna/SOC-Automation-Project/blob/main/Sysmon-Install

After Downloading Extact the sysmon zip file and Download sysmon config file as raw file and replace it in extracted sysmon folder

Now Open the Windows Powershell with Administartion Access.
Now Access the directory in which the sysmon folder is located by using command cd "directoy path"

Now it will redirect to directory now use command ".\sysmon64.exe -i sysmonconfig.xml'
.\sysmon64.exe - Installation file
-i command to install optionally take a configuration file
sysmonconfig.xml - File download from github used to configure the sysmon installtion

Once CLI Installtion Complete, You will be displayed with GUI Installtion and process as per procedure

To Recheck Installation:
Click Windows key and type service over the services running you can find Sysmon
Also you can find in Event viewer
Click Windows key and type event viewer, Once event Viewer is opened
Application and Services Log -> Microsoft -> Windows -> You need to drag down until you find Sysmon

"Ubuntu Cloud Setup"
Oceand-Digital Cloud Platform 
Requirement:
Name: Wazuh
Create Droplet/Cloud (Host was selected by near Data Center)
OS : Ubuntu 22.04 (LTS) x64
CPU : 2 Processors Premium Intel DIsk NVMe SSD ( Any CPU with good speeds Work)
Ram : 8GB
SSD : 120 GB
Transfer Speed : 2TB (Recommened) 5TB (Used)

Once the Cloud or Droplet is created. 
Create Firewall for Extra protection
In Inbound Rules Change All TCP Sources to your Own "IP Addresses" - Mention IPV4 Address in Allowed List. You can find IP address by typing in net MyIPAddress and you can find in website.
ALL UDP Sources to your Own "IP Addresses" - Mention IPV4 Address in Allowed List.
Create Fire Wall
Once Firewall is created, Use the created firewall as protection for the cloud/Droplet.

Once it is created Use IPV4 Address of created Droplet/Cloud and lanuch console of Wazuh
Use Command to update : "apt-get update && apt-get upgrade -y" Once the updates got installed.
Use Command from below link and run all commands one by one : https://github.com/Tagurkrishna/SOC-Automation-Project/blob/main/Wazuh-Install-Instructions

You Will see User name and Password Kindly note it down. 
If you miss to note it down they is command in link use it to get password for complete Wazuh Dashboard.

Now copy IPV4 address of Wazuh Droplet and open in your browser by inserting https:"ipv4 Address of Wazuh"

A Login Page of Wazuh will apear use User ID and Password to login.

With the same Procedure Create another Droplet and name it as thehive and configuration is mentioned in link provide below.
Install all the required software with the above link one by one : https://github.com/Tagurkrishna/SOC-Automation-Project/blob/main/TheHive-Install-Instructions.

Configuring TheHive & Wazuh Server

Here are the steps to configure the Hive server:

Edit Cassandra configuration file path: /etc/cassandra/cassandra.yaml
Nano /etc/cassandra/cassandra.yaml
To search use (Control + W) or (Control + Q)
Change listen_address and RPC_address to the public IP of the Hive server.
Change seed_address to the public IP of the Hive server.
Stop Cassandra service: systemctl stop cassandra.
And Save it with by using (Control + X) and press Y and hit enter. It will be saved
Remove old files: rm -rf /var/lib/cassandra/*.

After Every changes we make we need to restart the system to get it updated and start with all the configuration.
Start Cassandra service: systemctl start cassandra.
Check Cassandra service status: systemctl status cassandra.
Edit Elasticsearch configuration file: /etc/elasticsearch/elasticsearch.yml
To search use (Control + W) or (Control + Q)
Uncomment cluster name and change it to the Hive server name.
Uncomment network host and set it to the public IP of the Hive server.
Uncomment http port (optional).
Uncomment discovery seed or cluster initial master node (optional).
And Save it with by using (Control + X) and press Y and hit enter. It will be saved

After Every changes we make we need to restart the system to get it updated and start with all the configuration.
Start Elasticsearch service: systemctl start elasticsearch.
Enable Elasticsearch service: systemctl enable elasticsearch.
Check Elasticsearch service status: systemctl status elasticsearch.

Check whether we have access to thehive file path
ls -la /opt/thp/
If Not Change Access
Change owner and group of the Hive directory to The Hive user and group: chown -R TheHive:TheHive /opt/thehive.
Edit Hive configuration file: /etc/thehive/application.conf.

Change in database and index Comment Column
host name to the public IP of the Hive server.
Change cluster name for Cassandra to the name you specified.
Change host name to the public IP of the Hive server.
Change storage path to a directory owned by The Hive user and group.(localfs.location = /opt/thp/thehive/files)
but as we changed the ownership to same directory no need to modify it.
Change application.basedURL to the public IP of the Hive server.
And Save it with by using (Control + X) and press Y and hit enter. It will be saved

Start Hive service: systemctl start thehive.
Enable Hive service: systemctl enable thehive.
Check Hive service status: systemctl status thehive.
Hive server should now be up and running. You can access the Hive dashboard by navigating to the public IP of the Hive server with port 9000 and logging in with the default credentials (admin:admin and password:secret).

Here are the steps to configure Wazuh server:

Log into Wazuh dashboard using the administrative credentials obtained.(If you forgot password refer line 62)
Add an agent by clicking on ADD agent and selecting Windows.
Server address: Public IP of Wazuh server.
Assign an agent name (optional).
Copy the provided command and run it on the Windows machine with administrative privileges to install the agent.
Start the service on the Windows machine: net start WazuhSVC (or start the service from Services).
Check the Wazuh dashboard. You should see the agent listed as active after a few seconds.
Now you have both Hive and Wazuh servers configured and working as expected.

Generating Telemetry from a Windows 10 machine

Configure ossec.conf file to ingest Sysmon logs:
Open the ossec.conf file located at: C:\Program Files (x86)\ossec-agent\ossec.conf
You can open the file with notepad as Administator. In the file, find the log analysis section.
Add a new local file tag under the <log_analysis> section.
Set the name of the location tag to “SysmonChannel's Name”
Find the Sysmon channel name by going to Event Viewer -> Applications and Services -> Microsoft-Windows -> Windows Security -> Right click on “Operational” -> Select Properties -> Copy the full name under “Channel”
Paste the copied channel name into the location tag under <application>.

Restart Wazuh service:
Open services.msc, Locate Wazuh service. Right-click on the service and select “Restart”
Verify Sysmon events are being ingested:
Open the Wasa dashboard
Go to Events -> Alerts Index
Search for “sysmon”

Download Mimikatz:
Make sure to disable Windows Defender or exclude your downloads folder before downloading Mimikatz.
Download Mimikatz and save it to your downloads folder.
Extract Mimikatz:
Right-click on the downloaded Mimikatz archive and select “Extract All”.
Run Mimikatz as administrator:
Open a PowerShell session with administrative privileges.
Change your directory to the location where you extracted Mimikatz.
Run the command: mimikatz.exe
Create a custom alert in Wazuh to detect Mimikatz:
Go to the Wazuh manager CLI and create a backup of the ossec.conf file. (Always Create Backup for Configuration files which will save during error cases)
Command : 
cp /var/ossec/etc/ossec.conf ~/ossec-backup.conf
Do check it by using command ls

Command: nano /var/ossec/etc/ossec.conf
Edit the ossec.conf file and change the <log_all> section to “yes” under the `<alerts>” section. This will allow Wazuh to log everything.
Restart the Wasa manager service by typing: system ctl restart wazuh-manager
Update the filebeat configuration file by typing: nano /etc/filebeat/filebeat.yml
Change the archives_enabled setting to “true”.
Restart the filebeat service by typing: systemctl restart filebeat
Create a new index pattern in the Wazuh dashboard by clicking on the hamburger icon in the top left corner and selecting “Stack Management” -> “Index Patterns”.
Name the new index pattern “Wazuh-Archives-*”.
Select the “timestamp” field for the time field.
Go to Discover in the Wasa dashboard and select the “Wazuh-Archives-*” index pattern from the dropdown menu.
Search for “mimikatz” in the search bar.

Create a custom rule to target Mimikatz:
Go to the Wazuh dashboard and click on the home button.
Select “Management” -> “Rules” -> “Manage Rule Files”.
Search for “sysmon” and select the rule “0800-sysmon_id_1.xml”.
Copy the rule and paste it into the local rule file in the custom rules section.
Modify the copied rule:
Change the ID field to “100002”.
Change the level field to “15” for severity.
Change the “field_name” to “originalFileName”.(Do Mention name as it is in log even a lowercase will not trigger the alert)
Change the “value” to “mimikatz” to target Mimikatz specifically.
Modify the “description” field to a more descriptive message.
Modify the “MITRE_ID” field to “003” for credential dumping.
Save the rule.
Restart the Wazuh manager service.

After restarting the Wazuh-manager
now change the file name on Demo PC and try restarting the service now can find a alert in Wazuh dashboard even though the file name has changed the "orginalFileName" = Is set to mimikatz.

Now the Final Integration part using SOAR Platform(Shuffle)
Now we need to login in and create a account in Shuffle(https://shuffler.io/)
They are two environments in Shuffle one is Cloud and Another is Onprem Environment
Need to run on OnpremEnvironment which needs Orobous which is runned locally using Docker Installtion gudie(https://github.com/Shuffle/Shuffle/blob/main/.github/install-guide.md#orborus)
Once the installation is done you can start creating the workflow.
Click on Workflow Tabs on top left corner after logging.
Use Create workflow option to create new workflow and name the work flow and Usecases Select any save it and proceed.
You will be seen with Change me icon on workflow. Now from trigger section add Webhook and customize it by changing it name for better and clear understanding.
Now click on Change_me icon on workflow and for intialze checking find actions be as Repeat back to me and Call should be give as Execution Statement.
Copy Webhook URL from Webhook and place it on conf files of Wazuh, On wazuh console use command: nano /var/ossec/etc/ossec.conf and paste the command provide below between Ossec configuration and alerts by maintaining indendtation
 <integration>
     <name>shuffle</name>
     <hook_url>Link</hook_url>
     <level>15</level>
     <alert_format>json</alert_format>
 </integration>

And Save the file by using ctrl+X and Press Y and Press Enter to save file.
Use Command:
systemctl restart wazuh-manager.service 
Restart the Wazuh-manager after every configuration to get updated. And do start mimikatz on Demopc(Vm Ware Created)

On Shuffel start the Webhook URL and Run the execution or workflows you will can find sucessful exectuion if the exectuion takes more time then 30 Sec (Reconfirm installtion of Docker and check whether Docker has installed and configured with Onprem Environment correctly)
Succesful Execution, Select Change_me icon(Rename it for better understanding i used Hash_SHA256) and change the Action to Regex Capture Group
In field of input data Click Plus Button and it shows execution statement coloumn select Hash. input regex value on RegexValue Field based on Hash value you seen on exectuion of Webhook, If we dont know how to create one dont worry ask ChatGPt.
Return the execution to check all the hash values displaying in log. I selected hash values to inject it to Virustotal to get the detailed information of the file or walmare report.
Now create a account in VirusTotal and copy API. In shuffle search for VirusTotal and insert it in Workflow and customize it. Click on + beside authentication row and then paste the API key and submit it.
Select Get Hash Reports on Action filed and scroll down for Id Field click on + and slect Hash_SHA256 a drop down will appear select list and save the work flow and rerun it.You can find all the execution are success if you face any issue do recheck all the configuration Wazuh Vmware and rerun mimikatz on pc to get the report.

Open TheHive Ip address on web browser by port 9000. If you face any issue during login in do check all the services are running. Even after succesful running service if the issue still presist vist TheHive-Install-instructions folder for further resolution.
User : admin
password: secret
Click on users tab and add user and Give the required field(Login should be a email id which can be sample@test.com example) and create a user and select analyst in profile tab, Highlight the account and click preview and set a new password. 
Create a new user Change the type from normal to service and fill all the required fields, Profile feild as analyst.Highlight the account and click preview create a API key and copy that.
you can login using user credentials, interface is different and shows no cases.

Go to Shuffel On Apps section search for TheHive and use it in Workflow. Click on TheHIive Icon on authentication field click + and paste the API key, URL section copy and paste your Hive IP Address with port 9000.
FInd Action -> Create a Alert
Description -> "Mimikatz detected on host: (use exceution argument and select computer) from user: (select user from Execution Argument Field)" and we can select as much information we need for project purpose iam selecting two of them.
Flag -> False
Pap -> 2(As per documentation)
Severity -> 2
Source -> Wazuh
Sourceref -> "Rule:100002" (Rule no which is created in wazuh)
Summary -> "Mimikatz activity detected on host: (use exceution argument and select computer) and process id: (Select process id from Execution Argument) and CommandLine is: (Search for Command Line in Execution Argument)" We can take the information we required i selected these 3
Tags -> ["T1003"]
Title -> Slected from Excution Argument field named Title.
Tlp -> 2
Type -> Internal

Change the Firewall Setting add UDP with Port : 9000 and allow all IPV4.
Run the workflow, aftersuccesful competion you will recive a mail to your TheHive mail id.

With This The SOC Automation Projects Ends

Apart from TheHive we can automate by using Temp or Disposable or any domain Email id, Even add addtional security features like Ip Address filtering and blocking of unauthorized ip address.
Use Webflow Apps and triggers:
Wazuh
Email
HTTP
WebHook
Virustotal
UserInput

COnfigure and work these
